---
title: Structuring Context Between Agents
sidebarTitle: Handoff Protocol
description: How to structure context passing in multi-agent systems — what coordinators should include when delegating, what specialists should return, and procedural patterns for validation and iteration.
---

In a multi-agent system, reliable outcomes depend on how well context flows between Sub Agents. A coordinator that delegates with vague instructions gets vague results. A specialist that returns unstructured output makes aggregation fragile.

This page covers how to structure context passing and the procedural patterns that make agent behavior predictable.

## Coordinator to specialist: delegation context

When a coordinator delegates a subtask, its prompt should instruct it to provide structured context. The more specific the handoff, the better the specialist's output.

Include these elements when delegating:

```markdown
- **Objective:** What to accomplish
- **Why this is needed:** 1 sentence of context
- **Scope:** What to focus on
- **Non-goals:** What to avoid
- **Target files / areas:** Specific files or directories
- **Constraints:** Hard rules (must / must-not)
- **Required checks:** Tests, linters, commands to run
- **Output format:** What structure to return
- **"Done" means:** Clear definition of completion
- **If blocked:** Fallback behavior
```

<Tip>
If you already know the target files, include them. If the specialist should avoid modifying anything, say so explicitly and limit its tool access.
</Tip>

Not every delegation needs all of these — a quick data lookup might only need an objective and output format. But for complex subtasks, specificity prevents wasted effort.

## Specialist to coordinator: return format

Specialists should return structured results that the coordinator can parse and aggregate. Define this format in the specialist's prompt:

```markdown
### TL;DR (2-5 bullets)

### Findings (prioritized)
- **Critical:** blocking issues
- **Warnings:** should-fix issues
- **Suggestions:** nice-to-have improvements

### Evidence
- Files + line ranges (or code excerpts kept short)
- Commands run + key outputs (truncated)

### Recommended next actions
1. Highest priority
2. Second priority

### Open questions
- Only list what materially affects next steps
```

Consistent return formats across all specialists make the coordinator's aggregation job straightforward.

## Patterns for multi-step workflows

### Pattern 1: One-shot delegation

The coordinator delegates a self-contained task and gets back a single comprehensive result.

**Best when:**
- The task is self-contained
- The coordinator will handle any follow-up steps

### Pattern 2: Sequential delegation

The coordinator delegates to specialists in sequence, passing relevant context from one phase to the next.

**Best when:**
- The task has distinct phases (research, then plan, then implement)
- Each phase builds on the previous one's output

<Steps>
  <Step>
    Coordinator delegates to specialist A and gets results
  </Step>
  <Step>
    Coordinator extracts the relevant pieces and delegates to specialist B with that context
  </Step>
  <Step>
    Repeat for additional phases
  </Step>
</Steps>

<Warning>
Avoid copying entire conversation histories between specialists. Extract only the minimal context needed for the next phase — this keeps prompts focused and avoids token bloat.
</Warning>

### Pattern 3: Parallel delegation

The coordinator delegates independent subtasks to multiple specialists simultaneously, then aggregates the results.

**Best when:**
- Multiple analyses are independent (security review + docs review)
- You want faster results through parallelism

## Procedural patterns

When agent tasks involve iteration, validation, or error handling, encode these patterns in the Sub Agent's prompt to make behavior predictable and bounded.

### Validation loops

Use when an agent needs to verify its work before returning.

**Pattern:** Do → Verify → Fix (if needed) → Re-verify → Return

```markdown
## Validation loop

1. Complete the implementation
2. Run tests and capture output
3. If tests fail:
   - Fix the failing tests (max 2 fix attempts)
   - Re-run tests after each fix
4. If tests still fail after 2 attempts:
   - Return findings with status: BLOCKED
   - Include error output and what you tried
5. If tests pass: return findings with status: COMPLETE
```

**Key elements:**
- Bounded iterations (max N attempts)
- Clear termination condition
- Explicit failure path with useful output

### Iteration policies

Use when a task may need multiple passes:

```markdown
## Iteration policy

- **Max iterations:** 3
- **Loop-back when:**
  - New issues discovered that weren't in the original scope
  - Review feedback requires changes
- **Terminate when:**
  - All issues resolved, OR
  - Max iterations reached, OR
  - Blocked on external dependency
- **On termination:** return findings with current status
  and remaining work
```

### Error handling

Use when an agent might encounter errors that shouldn't crash the entire task:

```markdown
## Error handling

- If file read fails: skip that file, note it in findings,
  continue with others
- If tests won't run: return what you have with
  status: BLOCKED and the error
- If API calls fail: retry once, then report the failure
- Never: silently swallow errors or proceed as if nothing happened
```

### Decision trees

Use when an agent needs to choose between paths based on conditions:

```markdown
## Handling different file types

If the file is a test file (*.test.ts, *.spec.ts):
  → Focus on test coverage and assertions
  → Skip style/formatting issues

If the file is a config file (*.config.*, *.json):
  → Check for security issues (exposed secrets, unsafe defaults)
  → Skip code quality checks

Otherwise:
  → Apply full review checklist
```

### Severity levels

Define consistent severity levels so all agents in your system categorize findings the same way:

| Level | Meaning | Examples |
|-------|---------|---------|
| **CRITICAL** | Must fix before proceeding; blocks the task | Security vulnerabilities, data loss risks, breaking API changes |
| **HIGH** | Should fix; significant impact | Bugs affecting users, performance regressions, missing error handling |
| **MEDIUM** | Worth fixing; moderate impact | Code quality issues, missing tests, inconsistent patterns |
| **LOW** | Nice to have; minor improvement | Style preferences, minor refactoring, documentation gaps |

### Combining patterns

For complex agents, combine these patterns into a cohesive workflow:

```markdown
## Workflow

1. Gather context (read files, understand scope)
2. Perform analysis
3. **Validation loop:**
   - Run automated checks
   - If checks fail: fix and re-run (max 2 attempts)
   - If still failing: return with status: BLOCKED
4. Return findings with severity classification

## Iteration policy

- Max iterations: 2
- Loop-back when: new scope discovered or blocking issue resolved
- Terminate when: all CRITICAL/HIGH issues addressed or max
  iterations reached

## Error handling

- If file not found: skip and note in findings
- If blocked: return partial findings with clear
  "what's missing" section
```
